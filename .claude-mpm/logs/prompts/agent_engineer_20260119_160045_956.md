---
timestamp: 2026-01-19T16:00:45.956130+00:00
type: agent_engineer
metadata:
  {
    'agent_type': 'engineer',
    'agent_id': 'engineer_4022cdf5-d9e6-4ed3-a6c0-704bd03066aa',
    'session_id': '4022cdf5-d9e6-4ed3-a6c0-704bd03066aa',
    'delegation_context':
      {
        'description': 'Implement R4 Content Extraction Pipeline',
        'timestamp': '2026-01-19T16:00:45.954707+00:00'
      }
  }
---

AGENT MEMORY - PROJECT-SPECIFIC KNOWLEDGE:

# Agent Memory: engineer

<!-- Last Updated: 2026-01-19T15:48:05.096598+00:00Z -->

INSTRUCTIONS: Review your memory above before proceeding. Apply learned patterns and avoid known mistakes.

## Task: Implement R4 - Content Extraction Pipeline

Implement the URL content extraction pipeline for article-mind-service following the detailed plan.

### Plan Location

Read and follow: /export/workspace/article-mind/docs/plans/plan-R4-content-extraction.md

### Research Reference

Review: /export/workspace/article-mind/docs/research/python-content-extraction-libraries-2025.md

### Key Requirements

1. **Technology Stack** (per research):
   - HTML extraction: trafilatura (primary), newspaper4k (fallback)
   - PDF extraction: PyMuPDF + pymupdf4llm (AGPL acceptable)
   - JS-rendered pages: Playwright (when needed)
   - HTTP client: httpx (async)

2. **Module Structure** - Create `src/article_mind_service/extraction/`:

   ```
   extraction/
   ├── __init__.py
   ├── base.py               # Abstract base extractor, ExtractionResult dataclass
   ├── html_extractor.py     # trafilatura + newspaper4k fallback
   ├── pdf_extractor.py      # PyMuPDF extraction
   ├── js_extractor.py       # Playwright for JS-rendered pages (optional)
   ├── pipeline.py           # Orchestration - detect type, route to extractor
   ├── content_type.py       # Content type detection (HEAD request, URL patterns)
   ├── utils.py              # Content cleaning, text normalization
   └── exceptions.py         # Custom exceptions
   ```

3. **Content Type Detection**:
   - HEAD request to check Content-Type header
   - URL pattern detection (.pdf extension)
   - Response content sniffing as fallback

4. **Extraction Pipeline Flow**:

   ```
   URL → Detect Content Type → Fetch → Extract → Clean → Return
   ```

5. **ExtractionResult Dataclass**:

   ```python
   @dataclass
   class ExtractionResult:
       content: str           # Extracted text
       title: str | None      # Page/document title
       success: bool
       error: str | None
       metadata: dict         # Author, date, etc.
   ```

6. **HTML Extractor**:
   - Use trafilatura.extract() with favor_recall=True
   - Fallback to newspaper4k if trafilatura fails
   - Extract title, author, publish date

7. **PDF Extractor**:
   - Use pymupdf4llm.to_markdown() for clean extraction
   - Fallback to basic PyMuPDF text extraction
   - Handle multi-page documents

8. **API Integration**:
   - Add endpoint: POST /api/v1/sessions/{session_id}/articles/{article_id}/extract
   - Trigger extraction manually (for now, async workers later)
   - Update article.extraction_status and article.content_text

9. **Configuration** (.env):
   ```
   EXTRACTION_TIMEOUT_SECONDS=30
   EXTRACTION_MAX_CONTENT_LENGTH=10000000
   EXTRACTION_USER_AGENT=ArticleMind/1.0
   ```

### Dependencies to Add

Update pyproject.toml with:

- trafilatura
- newspaper4k
- pymupdf
- pymupdf4llm
- httpx (likely already present)
- playwright (optional, for JS pages)

### Working Directory

/export/workspace/article-mind/article-mind-service/

### Quality Requirements

- All code passes: make lint, make typecheck
- Unit tests for extractors with mock responses
- Integration test for pipeline

Implement the complete R4 extraction pipeline, run quality checks, and report results.
